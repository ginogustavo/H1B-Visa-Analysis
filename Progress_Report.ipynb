{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Progress_Report.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RFnPSdxLC6em"
      },
      "source": [
        "## Analysing H1B Acceptance Trends "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Uh8CJdwBJOAL"
      },
      "source": [
        "H1B visa is a nonimmigrant visa issued to gradute level applicants allowing them to work in the United States. The employer sponsors the H1B visa for workers with theoretical or technical expertise in specialized fields such as in IT, finance, accounting etc. An interesting fact about immigrant workers is that about 52 percent of new Silicon valley companies were founded by such workers during 1995 and 2005. Some famous CEOs like Indira Nooyi (Pepsico), Elon Musk (Tesla), Sundar Pichai (Google),Satya Nadella (Microsoft) once arrived to the US on a H1B visa.\\\n",
        "**Motivation**: Our team consists of five international gradute students, in the future we will be applying for H1B visa. The visa application process seems very long, complicated and uncertain. So we decided to understand this process and use Machine learning algorithms to predict the acceptance rate and trends of H1B visa. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kjQ8YI2GTfb6"
      },
      "source": [
        "### Data \n",
        "The data used in the project has been collected from <a href=\"https://www.foreignlaborcert.doleta.gov/performancedata.cfm\">the Office of Foreign Labor Certification (OFLC).</a>The Data provides insight into each petition with information such as the Job title, Wage, Employer, Worksite location etc. To get the dataset click on the above link-> click on Disclosure data -> scroll down to H1B data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZNTPm7WVCsm4",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_sSzHVSl3-bD",
        "colab": {}
      },
      "source": [
        "!pip install autocorrect\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk,warnings\n",
        "import clean_wage as cw\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "from statistics import mean\n",
        "nltk.download('words')\n",
        "from autocorrect import Speller \n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "from sklearn.preprocessing import OneHotEncoder #ONE HOT ENCODING\n",
        "from sklearn.ensemble import RandomForestClassifier #Build model - Random Forest Classifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FARuLUkuV7T8"
      },
      "source": [
        "### Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pleklaelV_xO"
      },
      "source": [
        "Before we begin working on our data we need to understand the traits of our data which we accomplish using EDA. We see that we have about 260 columns , not all 260 columns have essential information that contributes to our analysis. Hence we pick out the columns such as case status( Accepted/ Denied) ,Employer, Job title etc.We can look at all the colums and the types of object in each column using cleaned.info(). We also use cleaned['column_name'].value counts to find the classes in the column along with the count. For feature engineering we are converting quantitative data to categorical.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iCiYlOyXHHKJ",
        "colab": {}
      },
      "source": [
        "file=pd.read_csv('/content/gdrive/My Drive/H-1B_Disclosure_Data_FY2019.csv')#Read the csv file and store it in file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZxxeAh5SX0Bc",
        "colab": {}
      },
      "source": [
        "cleaned=file[['CASE_NUMBER','CASE_STATUS','CASE_SUBMITTED','DECISION_DATE','VISA_CLASS','FULL_TIME_POSITION','JOB_TITLE','SOC_CODE','SOC_TITLE',\\\n",
        "              'EMPLOYER_NAME','WAGE_RATE_OF_PAY_FROM_1','WAGE_UNIT_OF_PAY_1','NAICS_CODE','WORKSITE_CITY_1','WORKSITE_STATE_1']]\n",
        "cleaned.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BbgGJEB9XpO6",
        "colab": {}
      },
      "source": [
        "print(cleaned['VISA_CLASS'].value_counts()) # similarly we can find the categories in CASE_STATUS and 'FULL_TIME_POSITION'\n",
        "# Visa class has many categories which are not of use , we require only H1B visa type , hence we drop all records with other visa types\n",
        "cleaned.drop(labels=cleaned.loc[cleaned['VISA_CLASS']!='H-1B'].index , inplace=True)\n",
        "#In case status we can drop withdrawn records and we can change certified-withdrawn to certified\n",
        "cleaned.replace({\"CASE_STATUS\":\"CERTIFIED-WITHDRAWN\"},\"CERTIFIED\",inplace=True)\n",
        "cleaned.drop(labels=cleaned.loc[cleaned['CASE_STATUS']=='WITHDRAWN'].index , inplace=True)\n",
        "warnings.simplefilter(\"ignore\")\n",
        "print(cleaned.info())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F5SSKy8mVr01",
        "colab": {}
      },
      "source": [
        "#the column wages has a mix of both string and float value types and some record have the symbol '$' which we want to remove\n",
        "cleaned['WAGE_RATE_OF_PAY_FROM_1'].apply(type).value_counts()\n",
        "cleaned['WAGES']=cleaned['WAGE_RATE_OF_PAY_FROM_1'].apply(cw.clean_wages).astype('float')\n",
        "cleaned['WAGE_UNIT_OF_PAY_1'].value_counts()# the wage information that we have available has different unit of pay"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hCGTUT22Z6Bj",
        "colab": {}
      },
      "source": [
        "# we convert the different units of pay to the type 'Year'\n",
        "cleaned= cw.clean_wageUnit(np,cleaned)\n",
        "cleaned.drop(columns=['WAGE_RATE_OF_PAY_FROM_1','WAGE_UNIT_OF_PAY_1'],axis=1,inplace=True)#we can drop the columns as cleaning is complete\n",
        "cleaned.dropna(inplace=True)# We can check if we have null records using cleaned.info() and drop null records"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M03_5gLDxgYT",
        "colab": {}
      },
      "source": [
        "cleaned['JOB_TITLE']=cleaned.JOB_TITLE.apply(lambda txt: \" \".join([cw.remove_num(i) for i in txt.lower().split()]))\n",
        "cleaned['JOB_TITLE']=cleaned['JOB_TITLE'].str.replace(',', '')\n",
        "cleaned['SOC_TITLE']=cleaned.SOC_TITLE.apply(lambda txt: \" \".join([cw.remove_num(i) for i in txt.lower().split()]))\n",
        "cleaned['SOC_TITLE']=cleaned['SOC_TITLE'].str.replace(',', '')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3DxeRz6Mxkx1",
        "colab": {}
      },
      "source": [
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "words = set(nltk.corpus.words.words())\n",
        "spell = Speller()\n",
        "def lemmatize_text(text):\n",
        "     return lemmatizer.lemmatize(text)\n",
        "def spelling_checker(text):\n",
        "     return spell(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zMiGTMl414Mq",
        "colab": {}
      },
      "source": [
        "cleaned['JOB_TITLE']=cleaned.JOB_TITLE.apply(lambda txt: \" \".join([lemmatize_text(i) for i in txt.lower().split()]))\n",
        "cleaned['JOB_TITLE']=cleaned.JOB_TITLE.apply(lambda txt: \" \".join([spelling_checker(i) for i in txt.lower().split()]))\n",
        "cleaned['SOC_TITLE']=cleaned.SOC_TITLE.apply(lambda txt: \" \".join([lemmatize_text(i) for i in txt.lower().split()]))\n",
        "cleaned['SOC_TITLE']=cleaned.SOC_TITLE.apply(lambda txt: \" \".join([spelling_checker(i) for i in txt.lower().split()]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iBMWRKQo14Mv",
        "colab": {}
      },
      "source": [
        "cleaned['WAGE_CATEGORY'] = cleaned['WAGES'].apply(cw.wage_feature_eng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IARZcE10wHBl",
        "colab": {}
      },
      "source": [
        "cleaned['EMPLOYER_NAME'].value_counts()\n",
        "Top_Employer=cleaned['EMPLOYER_NAME'].value_counts()[:10]\n",
        "plt.figure(figsize=[8,8])\n",
        "ax=sns.barplot(y=Top_Employer.index,x=Top_Employer.values,palette=sns.color_palette('viridis',10))\n",
        "ax.tick_params(labelsize=12)\n",
        "for i, v in enumerate(Top_Employer.values): \n",
        "    ax.text(.5, i, v,fontsize=15,color='white',weight='bold')\n",
        "plt.title('Top 10 Companies sponsoring H1B Visa in 2019', fontsize=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pdms5n6Fz7SO",
        "colab": {}
      },
      "source": [
        "cleaned= cw.clean_states(cleaned)\n",
        "cleaned= cw.drop_less_significant(cleaned)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUiqxBoLrD_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_scnt,data_anlst,data_eng,mach_learn=cw.data_jobs(cleaned)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYoaW_cZJf1E",
        "colab_type": "text"
      },
      "source": [
        "## Are you a international student? Are you looking for jobs in Data Science domain?\n",
        "The below visualization shows median salary for four data science related jobs and the number of visa applications that are submitted for each job. This gives us insights about the jobs available for international students/workers about the job market for Data Science domain. We get to know the number of jobs available for each caegory as well as the median wage for each category. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUPXSnAX1A5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f,ax=plt.subplots(figsize=(8,6))\n",
        "bplot1=plt.boxplot([data_scnt[data_scnt['WAGES']<200000].WAGES,data_anlst[data_anlst['WAGES']<200000].WAGES,data_eng[data_eng['WAGES']<200000].WAGES,mach_learn[mach_learn['WAGES']<200000].WAGES],patch_artist=\"True\")\n",
        "ax.set_xticklabels(['Data Scientists','Data Analysts','Data Engineer','Machine Learning'],fontsize=15)\n",
        "ax.set_title('Salary Distribution for jobs in Data Science field in 2019', fontsize=15)\n",
        "ax.tick_params(labelsize=10)\n",
        "colors = ['blue','orange', 'green', 'red'] \n",
        "for patch, color in zip(bplot1['boxes'], colors): \n",
        "  patch.set_facecolor(color)\n",
        "plt.show()\n",
        "datajobs=cw.data_concat(pd,data_scnt,data_anlst,data_eng,mach_learn)\n",
        "ax2=sns.countplot(x=\"data\", data=datajobs)\n",
        "ax2.set_title('Number of petitions for each jobs in Data Science field in 2019', fontsize=15)\n",
        "warnings.simplefilter(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wIUdVPMR14Nj",
        "colab": {}
      },
      "source": [
        "#CONVERTING CATEGORICAL COLUMNS INTO NUMERIC COLUMNS\n",
        "cleaned=cw.cat_to_num(cleaned)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lw2l9vMB14Nt"
      },
      "source": [
        "### Baseline classifier\n",
        "\n",
        "The baseline classifier is done with a basic model. In this case we are taking the mean of the labels ('certified' and 'denied' for H1B visa approvals). It will give us the base accuracy to which we will compare our classifier's accuracy. Our classifier should have a better accuracy than the baseline classifier accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kBUpRntv14Nu",
        "colab": {}
      },
      "source": [
        "# This step assigns a binary class label (0 or 1) to each label for H1B visa approval. \n",
        "def create_class_labels(processed_data):\n",
        "    y = np.where((processed_data['CASE_STATUS']== 1),1, 0)\n",
        "    return y\n",
        "X = cleaned['CASE_STATUS'].to_numpy()\n",
        "y = create_class_labels(cleaned)# Groundtruth labels for the dataset\n",
        "counts = cleaned['CASE_STATUS'].value_counts()\n",
        "print(counts)\n",
        "print('proportion: ', counts[0]/counts[1], ': 1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iwmIZYCt14Nz",
        "colab": {}
      },
      "source": [
        "def compute_accuracy(validation, predicted):\n",
        "    comp = prediction == validation \n",
        "    match_counts = np.count_nonzero(comp == True) \n",
        "    clasifier_accuracy = match_counts/len(validation)\n",
        "    return clasifier_accuracy  \n",
        "def compute_AUC(y, prediction):\n",
        "    auc = None\n",
        "    try:\n",
        "        auc = roc_auc_score(y, prediction)\n",
        "    except ValueError:\n",
        "        pass\n",
        "    return auc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1gr9AgXB14N4",
        "colab": {}
      },
      "source": [
        "accuracies = []\n",
        "AUCs = []\n",
        "kf = sklearn.model_selection.KFold(n_splits=4, random_state=1, shuffle=True)# Testing with K-folds \n",
        "for train_idx, test_idx in kf.split(X):\n",
        "    X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx] \n",
        "    prediction = blc.run_clasifier(X_train, y_train, X_test, np)\n",
        "    fold_accuracy = compute_accuracy(y_test, prediction)\n",
        "    fold_AUC = compute_AUC(y_test, prediction)\n",
        "    accuracies.append(fold_accuracy)\n",
        "    if fold_AUC != None: AUCs.append(fold_AUC)\n",
        "baseline_clasifier_accuracy = mean(accuracies)\n",
        "print('Baseline accuracy: ', baseline_clasifier_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2WJnr6p414N7",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)# Testing with regular split\n",
        "prediction = blc.run_clasifier(X_train, y_train, X_test, np)\n",
        "split_accuracy = compute_accuracy(y_test, prediction)\n",
        "split_AUC = compute_AUC(y_test, prediction)\n",
        "print('Baseline accuracy: ', split_accuracy)  \n",
        "print('AUC K-fold: ', mean(AUCs))\n",
        "print('AUC split (80-20): ', split_AUC)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Oyr0Q6LN14OA"
      },
      "source": [
        "The accuracy results of the baseline classifier is 0.99. This result is due to the highly imbalanced data, where there are 624682 CERTIFIED applications and 5158 DENIED applications. The proportion of it is 121.10934470725087 to 1. Therefore, a performance measure based on the accuracy is not a good one. A better performance measure in imbalanced data is the Area under the ROC Curve (AUC). It meassures the likelihood that given two random points (one from the positive and one from the negative class) the classifier will rank the point from the positive class higher than the one from the negative one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "me1Gx1mr14OO",
        "colab": {}
      },
      "source": [
        "Dataset = cleaned[[\"CASE_STATUS\", \"FULL_TIME_POSITION\",\"JOB_TITLE\", \"SOC_CODE\", \"SOC_TITLE\", \"EMPLOYER_NAME\", \"WORKSITE_STATE_1\", \"WAGE_CATEGORY\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Njki8NhcmyKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def soc_code(x):\n",
        "    if x in y:\n",
        "        return x\n",
        "    else:\n",
        "        return 0\n",
        "y = Dataset[\"SOC_CODE\"].value_counts().head(70)\n",
        "Dataset[\"TOP_SOC_CODE\"] = Dataset[\"SOC_CODE\"].apply(common_function)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlspFt7emyK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def common_function(x):\n",
        "    if x in y:\n",
        "        return x\n",
        "    else:\n",
        "        return \"others\"\n",
        "y = Dataset[\"JOB_TITLE\"].value_counts().head(72)\n",
        "Dataset[\"JOB_POSITION\"] = Dataset[\"JOB_TITLE\"].apply(common_function)\n",
        "y = Dataset[\"SOC_TITLE\"].value_counts().head(70)\n",
        "Dataset[\"TOP_SOC_TITLE\"] = Dataset[\"SOC_TITLE\"].apply(common_function)\n",
        "y = Dataset[\"EMPLOYER_NAME\"].value_counts().head(70)\n",
        "Dataset[\"TOP_EMPLOYER\"] = Dataset[\"EMPLOYER_NAME\"].apply(common_function)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JdKSXCt714Ol",
        "colab": {}
      },
      "source": [
        "Dataset.drop(columns=['JOB_TITLE','SOC_CODE','SOC_TITLE','EMPLOYER_NAME',],axis=1,inplace=True)\n",
        "Encoding = OneHotEncoder(handle_unknown='ignore',sparse = True)\n",
        "Encoding_df = pd.DataFrame(Encoding.fit_transform(Dataset[[\"WORKSITE_STATE_1\",\"JOB_POSITION\",\"TOP_SOC_CODE\",\"TOP_SOC_TITLE\",\"TOP_EMPLOYER\"]]).toarray())\n",
        "Dataset = Dataset.join(Encoding_df)\n",
        "Dataset.drop(columns=['WORKSITE_STATE_1','JOB_POSITION','TOP_SOC_CODE','TOP_SOC_TITLE','TOP_EMPLOYER','WAGE_CATEGORY'],axis=1,inplace=True)\n",
        "Y = Dataset['CASE_STATUS'].values\n",
        "X = Encoding_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wtqqupdU14O1",
        "colab": {}
      },
      "source": [
        "Y = Dataset['CASE_STATUS'].values\n",
        "X = Encoding_df\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=20)#Split the date into training and test set\n",
        "model_clf = RandomForestClassifier(n_jobs=2,random_state=0)\n",
        "model_clf.fit(X_train,y_train)#train the model\n",
        "prediction_test = model_clf.predict(X_test)#test the model (predict with our test data)\n",
        "print(\"Accuracy = \", metrics.accuracy_score(y_test, prediction_test))#compare with original value, Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HMPmHHbo14PE"
      },
      "source": [
        "###Reflection\n",
        "What is the hardest part of the project that you’ve encountered so far?\n",
        "Setting up the data for visualization and ML analysis, e.g. same job title is cluttered with different words, integers, and punctuation characters. Encoding the dataset to be used in the Classifier was one the hardest part, which was later resolved by considering only the most values .\n",
        "\n",
        "Are there any concrete results you can show at this point? If not, why not?\n",
        "The concrete result that we have achieved is the acceptance of the H1B visa can be predicted, based on the Random-Forest-Classifier, which has shown 99% accuracy.\n",
        "\n",
        "Going forward, what are the current biggest problems you’re facing?\n",
        "One the issues we might encounter is using 'SMOTE' to balance out our data in a better way and handling additional data that will be included.\n",
        "\n",
        "Do you think you are on track with your project? If not, what parts do you need to dedicate more time to?\n",
        "We are track with the project and will be able to accomplish all the results within the stipulated timeframe.\n",
        "\n",
        "Given your initial exploration of the data, is it worth proceeding with your project, why? If not, how are you going to change your project and why do you think it’s better than your current results?\n",
        "On the lines of the initial exploration, we conclude that proceeding with are project is worthy.\n",
        "\n",
        "###Next steps:\n",
        "What you plan to accomplish in the next month and how you plan to evaluate whether your project achieved the goals you set for it?\n",
        "In the next month we plan to accomplish and present valid outcomes , we plan to apply another Machine-Learning Algorithm, predict the acceptance rates and provide another visualization based on the different states and their acceptance rates and also showcase the difference in the H1B visa acceptance after the policies that were enforced in the recent years. We will also combine the data from additional years."
      ]
    }
  ]
}